{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import emoji\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv into a dataframe, focus on tweets\n",
    "df = pd.read_csv(\"Tweets.csv\", header=None, usecols=[1])\n",
    "na = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to remove stopwords \n",
    "# 1. TweetTokenize the individual words\n",
    "# 2. convert to lowercase to match stopwords\n",
    "# 3. append non stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "def removeStopWords(words):\n",
    "    new_words = []\n",
    "    for x in words:\n",
    "        z = word_tokenize(x)\n",
    "        for q in z:\n",
    "            if q.lower() not in stop_words:\n",
    "                new_words.append(q.lower())\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stopwords\n",
    "nb = []\n",
    "for x in na:\n",
    "    nb.append(removeStopWords(x))    \n",
    "# print(nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to remove punctuations\n",
    "def remove_punctuations(words):\n",
    "    fc = []\n",
    "    for x in words:\n",
    "        fc.append(x.translate(str.maketrans('', '', string.punctuation)))\n",
    "    return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove punctuations\n",
    "nc = []\n",
    "for x in nb:\n",
    "    nc.append(remove_punctuations(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Remove single characters and empty array values\n",
    "def remove_single_characters_and_empty_values(words):\n",
    "    cv = []\n",
    "    for x in words:\n",
    "        if len(x) >1:\n",
    "            cv.append(x)\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove single characters and empty array values\n",
    "nd = []\n",
    "for x in nc:\n",
    "    nd.append(remove_single_characters_and_empty_values(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check for ascii characters\n",
    "def is_ascii(s):\n",
    "    return all(ord(c) < 128 for c in s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for Replacing non-ASCII characters with spaces\n",
    "def replace_non_ascii_with_space(words):\n",
    "    f = []\n",
    "    for x in words:\n",
    "        c = \"\"\n",
    "        for y in x:\n",
    "            c = c + (y if is_ascii(y) else \" \")\n",
    "        f.append(c)\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace non ascii characters with space\n",
    "ne = []\n",
    "for x in nd:\n",
    "    ne.append(replace_non_ascii_with_space(x))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to remove html tags\n",
    "def remove_html_tags(words):\n",
    "    f = []\n",
    "    for x in words:\n",
    "        f.append(re.compile(r'<[^>]+>').sub('', x))\n",
    "    return f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all html tags\n",
    "nf = []\n",
    "for x in ne:\n",
    "    nf.append(remove_html_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to remove emojis\n",
    "def remove_emoticons(words):\n",
    "    xc = []\n",
    "    for x in words:\n",
    "        xc.append(re.sub(emoji.get_emoji_regexp(), r\"\", x))\n",
    "    return xc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove emojis\n",
    "ng = []\n",
    "for x in nf:\n",
    "    ng.append(remove_emoticons(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second round of stopwords removal, remove swahili conjunctions and single characters with no meaning\n",
    "more_stop_words = (\"rt\", \"nt\", \"https\", \"ni\", \"http\", \"ya\", \"na\", \"wa\")\n",
    "for x in more_stop_words:\n",
    "    stop_words.append(x)\n",
    "# print(stop_words)\n",
    "def removeSwahiliStopWords(words):\n",
    "    new_words = []\n",
    "    for x in words:\n",
    "        if x not in stop_words:\n",
    "                new_words.append(x)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = []\n",
    "for x in ng:\n",
    "    nh.append(removeSwahiliStopWords(x))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete two letted words as they do not hold much meaning\n",
    "def deleteTwoWordCharacters(words):\n",
    "    wd = []\n",
    "    for x in words:\n",
    "        if len(x) > 2:\n",
    "            wd.append(x)\n",
    "    return wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "ni = []\n",
    "for x in nh:\n",
    "    ni.append(deleteTwoWordCharacters(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove numbers and any characters which may contain  numbers\n",
    "import numbers\n",
    "import re\n",
    "def removeNumbers(words):\n",
    "    wd = []\n",
    "    for x in words:\n",
    "        if not x.isdigit():\n",
    "            if not bool(re.search(r'\\d', x)):\n",
    "                wd.append(x)\n",
    "    return wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "nj = []\n",
    "for x in ni:\n",
    "    nj.append(removeNumbers(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
